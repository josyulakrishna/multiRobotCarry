{"timesteps_total": 788, "episodes_total": 2, "train_reward_min": -239.40000000000003, "train_reward_mean": -239.40000000000003, "train_reward_med": -239.40000000000003, "train_reward_max": -239.40000000000003, "train_top_5_reward_avg": -239.40000000000003, "evaluate_reward_min": -220.99999999999994, "evaluate_reward_mean": -190.08499999999998, "evaluate_reward_med": -208.85, "evaluate_reward_max": -121.69999999999999, "avg_timesteps_train": 394.0, "avg_timesteps_evaluate": 150.6, "eval_max_video": 0, "eval_min_video": 0, "total_timesteps": 788, "_runtime": 27, "_timestamp": 1669423682, "_step": 0}